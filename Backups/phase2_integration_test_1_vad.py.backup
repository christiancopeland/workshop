"""
Integration Test 1: Basic VAD Detection
Tests voice activity detection with real microphone input.
"""

import numpy as np
import time
from audio_realtime import RealtimeAudioCapture
from vad import VoiceActivityDetector
import logger as log


def test_vad_detection():
    """Test basic VAD with real microphone."""
    print("\n" + "="*60)
    print("INTEGRATION TEST 1: Voice Activity Detection")
    print("="*60)
    print("\nThis test verifies VAD detects your voice vs silence.")
    print("\nInstructions:")
    print("1. Wait for 'Listening...'")
    print("2. SPEAK into microphone for 2-3 seconds")
    print("3. PAUSE for 1-2 seconds")
    print("4. Repeat a few times")
    print("5. Press Ctrl+C to stop")
    print("\nStarting in 3 seconds...\n")
    time.sleep(3)
    
    # Initialize components
    # Blue USB mic configuration: 44.1kHz hardware, 16kHz for VAD
    vad = VoiceActivityDetector(
        threshold=0.5,
        min_speech_duration_ms=250,
        min_silence_duration_ms=300
    )
    
    # Configure for Blue Yeti (device 4, 44.1kHz, stereo)
    # Automatically resamples 44.1kHz ‚Üí 16kHz for VAD
    capture = RealtimeAudioCapture(
        sample_rate=16000,           # Target rate for VAD
        channels=2,                  # Blue Yeti is stereo
        frame_size=512,              # At 16kHz (exactly 512 samples guaranteed)
        device_id=4,                 # Blue Yeti mic (was 9, now corrected to 4)
        hardware_sample_rate=44100   # Mic's native rate
    )
    
    try:
        print("üé§ Listening for speech...")
        print("   (Speak to test detection, ambient noise should be ignored)")
        print()
        
        capture.start()
        
        frame_count = 0
        speech_count = 0
        silence_count = 0
        last_state = None
        
        while True:
            # Get audio frame (with short timeout to keep queue from filling)
            frame = capture.get_frame(timeout=0.05)
            if frame is None:
                continue
            
            # Verify frame size (debugging)
            if frame_count == 0:
                print(f"   First frame size: {len(frame)} samples (expected: 512)")
                if len(frame) != 512:
                    print(f"   ‚ö†Ô∏è WARNING: Frame size mismatch! VAD may fail.")
            
            # Process through VAD
            vad.process_frame(frame)
            frame_count += 1
            
            # Check state
            current_state = vad.is_speaking
            
            # Log state changes
            if current_state != last_state:
                if current_state:
                    speech_count += 1
                    print(f"üé§ SPEECH DETECTED! (transition #{speech_count})")
                    print(f"   Probability: {vad.get_probability():.3f}")
                else:
                    silence_count += 1
                    print(f"üîá Silence (transition #{silence_count})")
                    print(f"   Probability: {vad.get_probability():.3f}")
                
                last_state = current_state
            
            # Periodic stats (every 200 frames = ~6.4 seconds)
            if frame_count % 200 == 0:
                stats = vad.get_stats()
                total_speech = stats['total_speech_frames']
                total_silence = stats['total_silence_frames']
                total = total_speech + total_silence
                
                if total > 0:
                    speech_pct = (total_speech / total) * 100
                    print(f"\nüìä Stats: {frame_count} frames processed")
                    print(f"   Speech: {total_speech} frames ({speech_pct:.1f}%)")
                    print(f"   Silence: {total_silence} frames ({100-speech_pct:.1f}%)")
                    print(f"   Transitions: {stats['state_transitions']}")
                    print()
    
    except KeyboardInterrupt:
        print("\n\n‚ÑπÔ∏è  Test stopped by user")
        
        # Final stats
        stats = vad.get_stats()
        print("\n" + "="*60)
        print("FINAL STATISTICS")
        print("="*60)
        print(f"Total frames processed: {frame_count}")
        print(f"Speech frames: {stats['total_speech_frames']}")
        print(f"Silence frames: {stats['total_silence_frames']}")
        print(f"State transitions: {stats['state_transitions']}")
        print(f"Speech transitions: {speech_count}")
        print(f"Silence transitions: {silence_count}")
        print()
        
        # Assessment
        print("="*60)
        print("ASSESSMENT")
        print("="*60)
        
        if speech_count > 0:
            print("‚úÖ PASS: VAD detected speech")
        else:
            print("‚ùå FAIL: No speech detected - check microphone or speak louder")
        
        if silence_count > 0:
            print("‚úÖ PASS: VAD detected silence")
        else:
            print("‚ö†Ô∏è  WARNING: No silence detected - constant noise?")
        
        if stats['state_transitions'] >= 2:
            print("‚úÖ PASS: Multiple state transitions (natural)")
        else:
            print("‚ö†Ô∏è  WARNING: Few transitions - try speaking and pausing more")
        
        print("\n" + "="*60)
        print("Test complete!")
        print("="*60 + "\n")
    
    finally:
        capture.stop()


if __name__ == "__main__":
    test_vad_detection()